{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Œ Implementation of a Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Coding a neural network from scratch is a great way to understand how they work. In this notebook, I will implement a neural network from scratch with basic python libraries such as **numpy** and **matplotlib**. There will also be implementations of **forward pass**, **backward pass**, and **gradient descent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Numpy version: 1.21.5\n",
      "Matplotlib version: 3.5.2\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib as plt\n",
    "\n",
    "def versions():\n",
    "    print(\"Python version: {}\".format(sys.version))\n",
    "    print(\"Numpy version: {}\".format(np.__version__))\n",
    "    print(\"Matplotlib version: {}\".format(plt._version.version)) # type: ignore\n",
    "    \n",
    "versions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Single Neuron"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neuron which is a part of the **hidden layer** of a neural network is a mathematical function that takes in some inputs, performs some calculations on them, and produces an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 44.64\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.5, 3.7]\n",
    "weights = [4.5 , 2.1, 8.7]\n",
    "\n",
    "bias = 2.7      # There is only one bias for a neuron.\n",
    "\n",
    "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\n",
    "\n",
    "output = round(output, 3)       # Reducing the size of te output\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We could define a function for the neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function of a single neuron with any input size\n",
    "\n",
    "def neuron(inputs, weights, bias):\n",
    "    output = 0\n",
    "    for i in range(len(inputs)):\n",
    "        output += inputs[i]*weights[i]\n",
    "    output += bias\n",
    "    \n",
    "    return round(output, 3)\n",
    "\n",
    "neuron(\n",
    "    [1.0, 2.5, 3.7],\n",
    "    [4.5 , 2.1, 8.7],\n",
    "    4.7\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Basic Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A layer is a **collection of neurons**. We can define a layer with specific amount of neurons with specific amount of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46.64, 32.52, 47.96]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer(inputs, weights, biases):\n",
    "    output = []\n",
    "    for i in range(len(biases)):\n",
    "        output.append(neuron(inputs, weights[i], biases[i]))\n",
    "        \n",
    "    return output  # Returns a list of outputs\n",
    "\n",
    "layer(\n",
    "    [1.0, 2.5, 3.7],\n",
    "    [[4.5 , 2.1, 8.7], [1.2, 3.4, 5.6], [7.8, 9.1, 2.3]],   # 3 neurons with 3 weights each\n",
    "    [4.7, 2.1, 8.9]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This layer function can be improved with extra parameters that describes the layer in more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.14, 39.02, 72.96, 53.82]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer(neuron_count, inputs, weights, biases):\n",
    "    output = []\n",
    "    for i in range(neuron_count):\n",
    "        try:\n",
    "            output.append(neuron(inputs, weights[i], biases[i]))\n",
    "        except IndexError:\n",
    "            print(\"Size of weights, inputs and biases must be equal to the number of neurons!\")\n",
    "            break\n",
    "    return output  # Returns a list of outputs\n",
    "\n",
    "layer(\n",
    "    4,  # Number of neurons\n",
    "    [1.0, 2.5, 3.7, 5.0],   # Number of inputs\n",
    "    [[4.5, 2.1, 8.7, 0.5], [1.2, 3.4, 5.6, 1.3], [7.8, 9.1, 2.3, 5,3], [8.8, 9.9, 1.1, 3,3]],   # 4 neurons with 4 weights each\n",
    "    [4.7, 2.1, 8.9, 1.2]   # 4 neurons with 1 bias each\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It's possible to define a layer using numpy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.14, 30.12, 30.94])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def layer_numpy(inputs, weights, biases):\n",
    "    return np.dot(weights, inputs) + biases\n",
    "\n",
    "layer_numpy(\n",
    "    [1.0, 2.5, 3.7],\n",
    "    [[4.5 , -2.1, 8.7], [-1.2, 3.4, 5.6], [7.8, 9.1, -2.3],],   # 3 neurons with 3 weights each\n",
    "    [4.7, 2.1, 8.9]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch of Inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple inputs can be passed to the layer at once. This is called a **batch**. A batch is a collection of inputs. **Batch size** effects the generalization of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of samples: (3, 4)\n",
      "Shape of weights: (3, 4)\n",
      "Shape of biases: (3,)\n"
     ]
    }
   ],
   "source": [
    "sample = [1.0, 2.0, 3.0, 2.5]   # Single sample with 4 features.\n",
    "\n",
    "samples = [\n",
    "    [1.0, 2.0, 3.0, 2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],  # 3 samples with 4 features each.\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "]\n",
    "\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1.0],\n",
    "    [0.5, -0.91, 0.26, -0.5],   # 4 neurons with 4 weights each.\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "]\n",
    "\n",
    "biases = [2.0, 3.0, 0.5]    # 3 neurons with 1 bias each.\n",
    "\n",
    "print(f\"Shape of samples: {np.shape(samples)}\\nShape of weights: {np.shape(weights)}\\nShape of biases: {np.shape(biases)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To be able to get the dot product of the batch and the weights, we need to transpose the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of samples: (3, 4)\n",
      "Shape of weights: (4, 3)\n",
      "Shape of biases: (3,)\n"
     ]
    }
   ],
   "source": [
    "weights = np.array(weights).T   # Transposing the weights matrix.\n",
    "print(f\"Shape of samples: {np.shape(samples)}\\nShape of weights: {np.shape(weights)}\\nShape of biases: {np.shape(biases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.64\n",
      "Shape of the first layer's output: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "output_l1 = np.dot(samples, weights) + biases   # Output of the first layer.\n",
    "print(f\"{output}\\nShape of the first layer's output: {np.shape(output_l1)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Another Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Layer\n",
    "weights_2 = [\n",
    "    [0.1, -0.14, 0.5],\n",
    "    [-0.5, 0.12, -0.33],   # 3 neurons with 3 weights each.\n",
    "    [-0.44, 0.73, -0.13]\n",
    "]\n",
    "\n",
    "biases_2 = [-1.0, 2.0, -0.5]    # 3 neurons with 1 bias each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n",
      "Shape of the second layer's output: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "weights_2 = np.array(weights_2).T   # Transposing the weights matrix.\n",
    "\n",
    "output_l2 = np.dot(output_l1, weights_2) + biases_2 # Output of the second layer.\n",
    "print(f\"{output_l2}\\nShape of the second layer's output: {np.shape(output_l2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layers can be defined as an object with a **forward** method. This method takes in a batch of inputs and returns a batch of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X = [\n",
    "    [1, 2, 3, 2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "]\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)  # Random weights with the same shape as the input and the number of neurons.\n",
    "        self.biases = np.zeros((1, n_neurons))  # Biases with the shape of (1, n_neurons)\n",
    "    def forwawrd(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
